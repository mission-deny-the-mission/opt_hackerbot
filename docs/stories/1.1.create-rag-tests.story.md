# Story 1.1: Create Comprehensive RAG Test Suite

**Epic**: Epic 1 - LLM Feature Stabilization
**Story ID**: 1.1
**Priority**: Critical
**Estimated Effort**: 2-3 days
**Dependencies**: None

---

## Status

**Draft**

---

## Story

**As a** developer,
**I want** to create thorough automated tests for the RAG system,
**so that** I can validate its correctness and establish performance baseline.

---

## Acceptance Criteria

1. Test file created: test/test_rag_comprehensive.rb
2. Tests cover document loading from all knowledge source types (MITRE ATT&CK, man pages, markdown)
3. Tests verify vector embedding generation and storage
4. Tests verify similarity search returns relevant results for sample queries
5. Tests validate RAG context formatting for LLM consumption
6. Edge cases tested: empty queries, no matches, large result sets
7. Test coverage >80% for rag/rag_manager.rb and related classes
8. All tests pass in Nix development environment

---

## Integration Verification

- **IV1**: Verify tests don't modify production knowledge bases
- **IV2**: Verify test execution time reasonable (<5 minutes for full suite)
- **IV3**: Verify tests can run offline (no external API dependencies for core functionality)

---

## Tasks / Subtasks

### Phase 1: Test Infrastructure Setup (AC: 1)

- [ ] **Task 1.1: Create Test File and Framework Setup**
  - [ ] Create test/test_rag_comprehensive.rb
  - [ ] Examine existing test patterns in test/test_helper.rb
  - [ ] Set up test framework (likely Minitest based on existing tests)
  - [ ] Create test class: `TestRAGComprehensive < Minitest::Test`
  - [ ] Add setup and teardown methods

- [ ] **Task 1.2: Create Test Fixtures**
  - [ ] Create test/fixtures/rag_test_data/ directory
  - [ ] Create sample man page content (simple test pages)
  - [ ] Create sample markdown documents
  - [ ] Create sample MITRE ATT&CK data (or use subset)
  - [ ] Create expected embedding samples (for verification)

- [ ] **Task 1.3: Set Up Test Configuration**
  - [ ] Create test RAG configuration (in-memory, isolated)
  - [ ] Configure test vector DB (ChromaDB in-memory mode)
  - [ ] Configure test embedding service (Ollama with small model, or mock)
  - [ ] Ensure tests use separate collections from production

### Phase 2: Document Loading Tests (AC: 2)

- [ ] **Task 2.1: Test MITRE ATT&CK Loading**
  - [ ] Test loading MITRE ATT&CK knowledge source
  - [ ] Verify documents created in vector DB
  - [ ] Verify document count matches expected
  - [ ] Verify document metadata is correct
  - [ ] Test loading with empty ATT&CK data

- [ ] **Task 2.2: Test Man Page Loading**
  - [ ] Test loading man pages from knowledge source
  - [ ] Verify man page content parsed correctly
  - [ ] Verify documents stored in vector DB
  - [ ] Test with various man page sections
  - [ ] Test with missing/malformed man pages (error handling)

- [ ] **Task 2.3: Test Markdown File Loading**
  - [ ] Test loading markdown documents
  - [ ] Verify markdown parsing and structuring
  - [ ] Verify documents stored correctly
  - [ ] Test with headers, lists, code blocks
  - [ ] Test with empty/malformed markdown

### Phase 3: Embedding and Storage Tests (AC: 3)

- [ ] **Task 3.1: Test Embedding Generation**
  - [ ] Test embedding service generates vectors for text
  - [ ] Verify vector dimensions are correct
  - [ ] Test batch embedding generation
  - [ ] Test embedding generation errors (graceful handling)
  - [ ] Verify embeddings are consistent for same text

- [ ] **Task 3.2: Test Vector DB Storage**
  - [ ] Test documents stored with embeddings in vector DB
  - [ ] Verify collection creation
  - [ ] Verify document IDs are unique
  - [ ] Test updating existing documents
  - [ ] Test document deletion (if supported)

- [ ] **Task 3.3: Test Metadata Handling**
  - [ ] Verify metadata stored with documents
  - [ ] Test retrieving documents by metadata
  - [ ] Test metadata filtering
  - [ ] Verify metadata integrity after storage/retrieval

### Phase 4: Similarity Search Tests (AC: 4)

- [ ] **Task 4.1: Test Basic Similarity Search**
  - [ ] Test search with simple queries
  - [ ] Verify relevant documents returned
  - [ ] Verify results ranked by relevance
  - [ ] Test search with different result limits
  - [ ] Verify no results for completely unrelated queries

- [ ] **Task 4.2: Test Search Accuracy**
  - [ ] Create queries with known expected results
  - [ ] Test cybersecurity-specific queries (e.g., "credential dumping", "port scanning")
  - [ ] Verify top results are actually relevant
  - [ ] Test synonym handling (if applicable)
  - [ ] Test multi-word query handling

- [ ] **Task 4.3: Test Search Performance**
  - [ ] Measure search latency for typical queries
  - [ ] Verify search completes within 5 seconds (NFR4)
  - [ ] Test search with large knowledge bases
  - [ ] Test concurrent searches (if applicable)

### Phase 5: Context Formatting Tests (AC: 5)

- [ ] **Task 5.1: Test Context Assembly**
  - [ ] Test RAG manager assembles context from search results
  - [ ] Verify context format suitable for LLM consumption
  - [ ] Test context truncation for large results
  - [ ] Verify important sections preserved during truncation
  - [ ] Test context with multiple document sources

- [ ] **Task 5.2: Test Context Quality**
  - [ ] Verify context is human-readable
  - [ ] Test context includes source references
  - [ ] Verify context relevance to query
  - [ ] Test context length constraints
  - [ ] Verify no garbled or corrupted text in context

### Phase 6: Edge Case and Error Handling Tests (AC: 6)

- [ ] **Task 6.1: Test Empty/Invalid Queries**
  - [ ] Test with empty string query
  - [ ] Test with null query
  - [ ] Test with very long query (>1000 characters)
  - [ ] Test with special characters
  - [ ] Verify graceful error handling

- [ ] **Task 6.2: Test No Matches Scenario**
  - [ ] Test queries that match nothing
  - [ ] Verify empty results handled gracefully
  - [ ] Test fallback behavior
  - [ ] Verify appropriate error messages

- [ ] **Task 6.3: Test Large Result Sets**
  - [ ] Test queries matching many documents
  - [ ] Verify result limiting works
  - [ ] Test memory usage with large results
  - [ ] Verify performance doesn't degrade

- [ ] **Task 6.4: Test Error Scenarios**
  - [ ] Test with vector DB unavailable
  - [ ] Test with embedding service unavailable
  - [ ] Test with corrupted knowledge base
  - [ ] Verify all errors logged with Print.err
  - [ ] Verify system doesn't crash on errors

### Phase 7: Coverage and Integration (AC: 7, 8)

- [ ] **Task 7.1: Measure Test Coverage**
  - [ ] Run tests with coverage tool (SimpleCov or similar)
  - [ ] Verify >80% coverage for rag/rag_manager.rb
  - [ ] Verify coverage for rag/vector_db_interface.rb
  - [ ] Verify coverage for rag/embedding_service_interface.rb
  - [ ] Identify untested code paths and add tests

- [ ] **Task 7.2: Run All Tests in Nix Environment**
  - [ ] Execute full test suite: `ruby test/test_rag_comprehensive.rb`
  - [ ] Verify all tests pass
  - [ ] Fix any failures
  - [ ] Verify tests complete in <5 minutes
  - [ ] Document any environment-specific requirements

- [ ] **Task 7.3: Integration Verification** (IV1, IV2, IV3)
  - [ ] **IV1**: Verify tests use isolated test data, not production
  - [ ] **IV2**: Measure and document total test execution time
  - [ ] **IV3**: Run tests offline (disable network), verify pass
  - [ ] Verify tests clean up after themselves (no temp files left)

---

## Dev Notes

### RAG System Architecture

**RAG Manager** (`rag/rag_manager.rb`):
- Main coordinator for RAG operations
- Methods to test: `get_relevant_documents`, `add_documents`, `search`, context formatting
- [Source: docs/development/architecture.md#245-261]

**Vector DB Interface** (`rag/vector_db_interface.rb`):
- Abstract interface for vector database operations
- Implementations: ChromaDB (in-memory and server-based)
- [Source: Codebase inspection]

**Embedding Service Interface** (`rag/embedding_service_interface.rb`):
- Abstract interface for embedding generation
- Implementations: OpenAI, Ollama
- [Source: Codebase inspection]

### Existing Test Patterns

**Test Framework**: Ruby Minitest (based on existing tests)
[Source: test/test_helper.rb, test/test_llm_client_base.rb]

**Test File Pattern**:
```ruby
require_relative 'test_helper'

class TestRAGComprehensive < Minitest::Test
  def setup
    # Initialize test RAG manager
  end

  def teardown
    # Clean up test resources
  end

  def test_something
    # Test implementation
  end
end
```

**Test Execution**:
```bash
ruby test/test_rag_comprehensive.rb
# or
ruby test/run_tests.rb  # Run all tests
```
[Source: Existing test files]

### Test Configuration Example

```ruby
def setup
  @rag_config = {
    vector_db: {
      provider: 'chromadb',
      mode: 'in_memory'  # Isolated from production
    },
    embedding_service: {
      provider: 'ollama',
      model: 'nomic-embed-text'  # Small, fast model for testing
    },
    collection_name: 'test_rag_collection'  # Separate from production
  }

  @rag_manager = RAGManager.new(@rag_config)
end

def teardown
  @rag_manager.cleanup if @rag_manager
end
```

### Knowledge Source Test Data

**MITRE ATT&CK Sample**:
```ruby
# Small subset of techniques for testing
test_attack_data = [
  {
    id: 'T1003',
    name: 'Credential Dumping',
    description: 'Tools and techniques for dumping credentials...',
    metadata: { tactic: 'credential-access' }
  },
  # ... more test data
]
```

**Man Page Sample**:
```
LS(1)                     User Commands                    LS(1)

NAME
       ls - list directory contents

SYNOPSIS
       ls [OPTION]... [FILE]...
...
```

**Markdown Sample**:
```markdown
# Lab 1: Port Scanning

## Objective
Learn to use nmap for network reconnaissance.

## Tools
- nmap
- netstat
...
```

### Performance Benchmarks

**Target Metrics** (from NFR4):
- Query response time: â‰¤ 5 seconds (excluding LLM inference)
- Document loading: â‰¤ 60 seconds for typical knowledge base
- Memory usage: â‰¤ 4GB for 1000+ documents

[Source: docs/prd.md#2.2 Non-Functional Requirements]

### Offline Testing

**CRITICAL**: Tests must pass without external network access

- Use Ollama for local embeddings (or mock embeddings)
- Use ChromaDB in-memory mode
- No OpenAI API calls in core tests
- Network tests should be optional/skipped in offline mode

[Source: docs/prd.md#2.3 CR4: Offline Operation Compatibility]

### Error Handling Pattern

```ruby
def test_error_scenario
  assert_raises(SomeError) do
    @rag_manager.method_that_should_fail
  end
end

def test_graceful_degradation
  result = @rag_manager.search_with_failures
  assert_nil result  # Should return nil, not crash
end
```

### Coverage Measurement

If using SimpleCov:
```ruby
# In test_helper.rb or top of test file
require 'simplecov'
SimpleCov.start do
  add_filter '/test/'
  add_group 'RAG System', 'rag/'
end
```

---

## Testing

### Testing Strategy for This Story

**This IS the testing story** - we're creating tests, not testing tests.

**Validation Approach**:
1. **Manual Verification**: Run test suite, verify all pass
2. **Coverage Check**: Measure code coverage, verify >80%
3. **Performance Check**: Measure test execution time, verify <5 minutes
4. **Offline Check**: Run tests without network, verify pass

### Test Execution Commands

```bash
# Run RAG comprehensive tests
ruby test/test_rag_comprehensive.rb

# Run with verbose output
ruby test/test_rag_comprehensive.rb --verbose

# Run in Nix environment
nix develop
ruby test/test_rag_comprehensive.rb

# Run all tests (optional)
ruby test/run_tests.rb
```

### Success Criteria

âœ… All tests pass
âœ… >80% code coverage on RAG manager
âœ… Tests complete in <5 minutes
âœ… Tests pass offline
âœ… No production data modified

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-17 | v1.0 | Initial story creation | SM Agent (Bob) |

---

## Dev Agent Record

_This section will be populated by the development agent during implementation._

### Agent Model Used

_To be filled by dev agent_

### Debug Log References

_To be filled by dev agent_

### Completion Notes

_To be filled by dev agent_

### File List

_To be filled by dev agent_

---

## QA Results

_This section will be populated by QA Agent after story completion._

---

**Story prepared by**: Scrum Master Agent (Bob)
**Ready for**: Developer Agent implementation (can proceed to Story 1.2)
**Next Story**: 1.2 - Implement RAG Performance Validation and Optimization (depends on this story completion)

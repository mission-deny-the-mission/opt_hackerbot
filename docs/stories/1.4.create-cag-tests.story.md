# Story 1.4: Create Comprehensive CAG Test Suite

**Epic**: Epic 1 - LLM Feature Stabilization
**Story ID**: 1.4
**Priority**: High
**Estimated Effort**: 2-3 days
**Dependencies**: Story 1.2 (CAG fix implementation complete)

---

## Status

**Draft**

---

## Story

**As a** developer,
**I want** to create thorough automated tests for the CAG system,
**so that** I can validate its correctness and establish performance baseline.

---

## Acceptance Criteria

1. Test file created: test/test_cag_comprehensive.rb
2. Tests cover document loading from all knowledge source types (MITRE ATT&CK, man pages, markdown)
3. Tests verify cache storage and persistence in memory
4. Tests verify cache retrieval returns correct cached content
5. Tests validate CAG context formatting for LLM consumption
6. Edge cases tested: empty queries, no matches, large cache sizes
7. Test coverage >80% for cag/cag_manager.rb and related classes
8. All tests pass in Nix development environment

---

## Integration Verification

- **IV1**: Verify tests don't modify production knowledge bases or caches
- **IV2**: Verify test execution time reasonable (<5 minutes for full suite)
- **IV3**: Verify tests can run offline (no external API dependencies for core functionality)

---

## Tasks / Subtasks

### Phase 1: Test Infrastructure Setup (AC: 1)

- [ ] **Task 1.1: Create Test File and Framework Setup**
  - [ ] Create test/test_cag_comprehensive.rb
  - [ ] Examine existing test patterns in test/test_helper.rb
  - [ ] Set up test framework (Minitest based on existing tests)
  - [ ] Create test class: `TestCAGComprehensive < Minitest::Test`
  - [ ] Add setup and teardown methods

- [ ] **Task 1.2: Create Test Fixtures**
  - [ ] Create test/fixtures/cag_test_data/ directory
  - [ ] Create sample man page content (simple test pages)
  - [ ] Create sample markdown documents
  - [ ] Create sample MITRE ATT&CK data (or use subset)
  - [ ] Create sample cached content for verification

- [ ] **Task 1.3: Set Up Test Configuration**
  - [ ] Create test CAG configuration (in-memory, isolated)
  - [ ] Configure test cache manager (separate from production)
  - [ ] Configure test knowledge graph (if used) or cache structure
  - [ ] Ensure tests use separate collections/caches from production

### Phase 2: Document Loading Tests (AC: 2)

- [ ] **Task 2.1: Test MITRE ATT&CK Loading**
  - [ ] Test loading MITRE ATT&CK knowledge source
  - [ ] Verify documents/triplets cached correctly
  - [ ] Verify cache entry count matches expected
  - [ ] Verify metadata is correct
  - [ ] Test loading with empty ATT&CK data

- [ ] **Task 2.2: Test Man Page Loading**
  - [ ] Test loading man pages from knowledge source
  - [ ] Verify man page content parsed correctly
  - [ ] Verify documents cached in CAG system
  - [ ] Test with various man page sections
  - [ ] Test with missing/malformed man pages (error handling)

- [ ] **Task 2.3: Test Markdown File Loading**
  - [ ] Test loading markdown documents (lab sheets)
  - [ ] Verify markdown parsing and structuring
  - [ ] Verify documents cached correctly
  - [ ] Test with headers, lists, code blocks
  - [ ] Test with empty/malformed markdown

### Phase 3: Cache Storage and Persistence Tests (AC: 3)

- [ ] **Task 3.1: Test Cache Storage**
  - [ ] Test documents stored in cache correctly
  - [ ] Verify cache structure (graph nodes/relationships OR hash map)
  - [ ] Verify document IDs are unique
  - [ ] Test updating existing cached documents
  - [ ] Test cache size management

- [ ] **Task 3.2: Test Cache Persistence in Memory**
  - [ ] Test cached documents persist after initial load
  - [ ] Verify cache survives multiple queries
  - [ ] Test cache doesn't leak or grow unbounded
  - [ ] Verify memory usage stays within bounds
  - [ ] Test cache cleanup (if applicable)

- [ ] **Task 3.3: Test Metadata Handling**
  - [ ] Verify metadata stored with cached documents
  - [ ] Test retrieving documents by metadata
  - [ ] Test metadata filtering
  - [ ] Verify metadata integrity after storage/retrieval

### Phase 4: Cache Retrieval Tests (AC: 4)

- [ ] **Task 4.1: Test Basic Cache Retrieval**
  - [ ] Test retrieval with simple queries
  - [ ] Verify correct cached documents returned
  - [ ] Verify results ranked appropriately (if applicable)
  - [ ] Test retrieval with different result limits
  - [ ] Verify no results for unrelated queries

- [ ] **Task 4.2: Test Retrieval Accuracy**
  - [ ] Create queries with known expected results
  - [ ] Test cybersecurity-specific queries (e.g., "credential dumping", "port scanning")
  - [ ] Verify top results are actually relevant
  - [ ] Test retrieval doesn't reload from source (uses cache)
  - [ ] Test multi-keyword query handling

- [ ] **Task 4.3: Test Retrieval Performance**
  - [ ] Measure retrieval latency for typical queries
  - [ ] Verify retrieval completes within 5 seconds (NFR4)
  - [ ] Test retrieval with large caches
  - [ ] Test concurrent retrievals (if applicable)

### Phase 5: Context Formatting Tests (AC: 5)

- [ ] **Task 5.1: Test Context Assembly**
  - [ ] Test CAG manager assembles context from cached results
  - [ ] Verify context format suitable for LLM consumption
  - [ ] Test context truncation for large results
  - [ ] Verify important sections preserved during truncation
  - [ ] Test context with multiple document sources

- [ ] **Task 5.2: Test Context Quality**
  - [ ] Verify context is human-readable
  - [ ] Test context includes source references
  - [ ] Verify context relevance to query
  - [ ] Test context length constraints
  - [ ] Verify no garbled or corrupted text in context

### Phase 6: Edge Case and Error Handling Tests (AC: 6)

- [ ] **Task 6.1: Test Empty/Invalid Queries**
  - [ ] Test with empty string query
  - [ ] Test with null query
  - [ ] Test with very long query (>1000 characters)
  - [ ] Test with special characters
  - [ ] Verify graceful error handling

- [ ] **Task 6.2: Test No Matches Scenario**
  - [ ] Test queries that match nothing in cache
  - [ ] Verify empty results handled gracefully
  - [ ] Test fallback behavior
  - [ ] Verify appropriate error messages

- [ ] **Task 6.3: Test Large Cache Sets**
  - [ ] Test with large number of cached documents
  - [ ] Verify cache limiting works
  - [ ] Test memory usage with large caches
  - [ ] Verify performance doesn't degrade

- [ ] **Task 6.4: Test Error Scenarios**
  - [ ] Test with cache unavailable
  - [ ] Test with corrupted cache data
  - [ ] Test with missing knowledge sources
  - [ ] Verify all errors logged with Print.err
  - [ ] Verify system doesn't crash on errors

### Phase 7: Coverage and Integration (AC: 7, 8)

- [ ] **Task 7.1: Measure Test Coverage**
  - [ ] Run tests with coverage tool (SimpleCov or similar)
  - [ ] Verify >80% coverage for cag/cag_manager.rb
  - [ ] Verify coverage for cache implementation (graph client or simplified cache)
  - [ ] Verify coverage for knowledge source CAG integration
  - [ ] Identify untested code paths and add tests

- [ ] **Task 7.2: Run All Tests in Nix Environment**
  - [ ] Execute full test suite: `ruby test/test_cag_comprehensive.rb`
  - [ ] Verify all tests pass
  - [ ] Fix any failures
  - [ ] Verify tests complete in <5 minutes
  - [ ] Document any environment-specific requirements

- [ ] **Task 7.3: Integration Verification** (IV1, IV2, IV3)
  - [ ] **IV1**: Verify tests use isolated test data, not production
  - [ ] **IV2**: Measure and document total test execution time
  - [ ] **IV3**: Run tests offline (disable network), verify pass
  - [ ] Verify tests clean up after themselves (no temp files left)

---

## Dev Notes

### CAG System Architecture

**CAG Manager** (`cag/cag_manager.rb`):
- Main coordinator for CAG operations
- Methods to test: `setup`, `extract_entities`, `expand_context_with_entities`, `get_context_for_query`
- Implementation may vary based on Story 1.2 approach (repaired graph vs simplified cache)
- [Source: docs/development/architecture.md#214-216]

**Cache Implementation** (varies based on Story 1.2 approach):
- **IF Approach A (repaired graph)**: Test in_memory_graph_client.rb
  - Node/relationship creation and retrieval
  - Index maintenance
  - Graph search functionality
- **IF Approach B (simplified cache)**: Test new simplified cache manager
  - Hash-based storage
  - Simple retrieval by ID or keyword
  - Pre-cached prompt approach (if used)
- [Source: Story 1.2 implementation decision]

**Knowledge Source Integration**:
- Test CAG triplet generation (if graph approach)
- Test simplified document caching (if simplified approach)
- [Source: knowledge_bases/sources/man_pages/man_page_knowledge.rb]

### Existing Test Patterns

**Test Framework**: Ruby Minitest (based on existing tests)
[Source: test/test_helper.rb, test/test_llm_client_base.rb]

**Test File Pattern**:
```ruby
require_relative 'test_helper'

class TestCAGComprehensive < Minitest::Test
  def setup
    # Initialize test CAG manager
  end

  def teardown
    # Clean up test resources
  end

  def test_something
    # Test implementation
  end
end
```

**Test Execution**:
```bash
ruby test/test_cag_comprehensive.rb
# or
ruby test/run_tests.rb  # Run all tests
```
[Source: Existing test files]

### Test Configuration Example

```ruby
def setup
  @cag_config = {
    cache_type: 'in_memory',  # Or 'graph' depending on implementation
    collection_name: 'test_cag_collection',  # Separate from production
    knowledge_sources: @test_knowledge_sources
  }

  @cag_manager = CAGManager.new(@cag_config)
end

def teardown
  @cag_manager.cleanup if @cag_manager
end
```

### Knowledge Source Test Data

**MITRE ATT&CK Sample**:
```ruby
# Small subset of techniques for testing
test_attack_data = [
  {
    id: 'T1003',
    name: 'Credential Dumping',
    description: 'Tools and techniques for dumping credentials...',
    metadata: { tactic: 'credential-access' }
  },
  # ... more test data
]
```

**Man Page Sample**:
```
LS(1)                     User Commands                    LS(1)

NAME
       ls - list directory contents

SYNOPSIS
       ls [OPTION]... [FILE]...
...
```

**Markdown Sample**:
```markdown
# Lab 1: Port Scanning

## Objective
Learn to use nmap for network reconnaissance.

## Tools
- nmap
- netstat
...
```

### Performance Benchmarks

**Target Metrics** (from NFR4):
- Query response time: ≤ 5 seconds (excluding LLM inference)
- Cache loading: ≤ 60 seconds for typical knowledge base
- Memory usage: ≤ 4GB for 1000+ documents

[Source: docs/prd.md#2.2 Non-Functional Requirements]

### Offline Testing

**CRITICAL**: Tests must pass without external network access

- Use local cache only
- No external API calls in core tests
- Network tests should be optional/skipped in offline mode

[Source: docs/prd.md#2.3 CR4: Offline Operation Compatibility]

### Error Handling Pattern

```ruby
def test_error_scenario
  assert_raises(SomeError) do
    @cag_manager.method_that_should_fail
  end
end

def test_graceful_degradation
  result = @cag_manager.search_with_failures
  assert_nil result  # Should return nil, not crash
end
```

### Coverage Measurement

If using SimpleCov:
```ruby
# In test_helper.rb or top of test file
require 'simplecov'
SimpleCov.start do
  add_filter '/test/'
  add_group 'CAG System', 'cag/'
end
```

### Adaptation Based on Story 1.2 Implementation

**IMPORTANT**: This test suite must adapt to the CAG implementation approach chosen in Story 1.2:

**IF Approach A (Repaired Graph)**:
- Test graph node/relationship operations
- Test graph search and traversal
- Test index maintenance
- Focus on `in_memory_graph_client.rb` coverage

**IF Approach B (Simplified Cache)**:
- Test hash-based storage/retrieval
- Test simple keyword matching
- Test cache size management
- Focus on new simplified cache manager coverage

**IF Approach C (RAG-Only Fallback)**:
- **This story may be CANCELLED**
- Skip CAG testing, focus on RAG (Story 1.3)

[Source: Story 1.2 task structure]

---

## Testing

### Testing Strategy for This Story

**This IS the testing story** - we're creating tests, not testing tests.

**Validation Approach**:
1. **Manual Verification**: Run test suite, verify all pass
2. **Coverage Check**: Measure code coverage, verify >80%
3. **Performance Check**: Measure test execution time, verify <5 minutes
4. **Offline Check**: Run tests without network, verify pass

### Test Execution Commands

```bash
# Run CAG comprehensive tests
ruby test/test_cag_comprehensive.rb

# Run with verbose output
ruby test/test_cag_comprehensive.rb --verbose

# Run in Nix environment
nix develop
ruby test/test_cag_comprehensive.rb

# Run all tests (optional)
ruby test/run_tests.rb
```

### Success Criteria

✅ All tests pass
✅ >80% code coverage on CAG manager
✅ Tests complete in <5 minutes
✅ Tests pass offline
✅ No production data modified

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-17 | v1.0 | Initial story creation | SM Agent (Bob) |

---

## Dev Agent Record

_This section will be populated by the development agent during implementation._

### Agent Model Used

_To be filled by dev agent_

### Debug Log References

_To be filled by dev agent_

### Completion Notes

_To be filled by dev agent_

### File List

_To be filled by dev agent_

---

## QA Results

_This section will be populated by QA Agent after story completion._

---

**Story prepared by**: Scrum Master Agent (Bob)
**Ready for**: Developer Agent implementation (after Story 1.2 complete)
**Next Story**: 1.5 - Implement RAG vs CAG Performance Comparison (depends on Stories 1.3 and 1.4)

**⚠️ CONDITIONAL STORY**: This story may be cancelled if Story 1.2 triggers RAG-only fallback (Approach C). If CAG is not implemented, skip to Story 1.5 (modified as "RAG Performance Validation").

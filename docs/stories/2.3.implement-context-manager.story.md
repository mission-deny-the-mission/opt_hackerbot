# Story 2.3: Implement Context Manager

**Epic**: Epic 2 - CAG System Implementation
**Story ID**: 2.3
**Priority**: Critical
**Estimated Effort**: 3-4 days
**Dependencies**: Story 2.2 (Knowledge Base Loader)

---

## Status

**Draft**

---

## Story

**As a** developer,
**I want** to implement the CAG context manager for intelligent document assembly and context window optimization,
**so that** the CAG system can efficiently manage long-context LLM windows with relevance-based document selection and context compression.

---

## Acceptance Criteria

1. File created: cag/context_manager.rb
2. Context manager assembles documents into optimized context for long-context LLMs
3. Relevance-based document selection implemented (prioritization by relevance scores)
4. Context window optimization handles size constraints (32k-128k token windows)
5. Context compression techniques implemented for large knowledge bases
6. Multi-turn conversation context management implemented
7. Context metadata tracking (document sources, relevance scores, compression ratio)
8. Integration with knowledge loader (from Story 2.2)
9. All methods tested with unit tests

---

## Integration Verification

- **IV1**: Verify context assembly doesn't exceed target model context window sizes
- **IV2**: Verify relevance-based selection prioritizes most relevant documents
- **IV3**: Verify context compression maintains semantic meaning and accuracy
- **IV4**: Verify multi-turn conversation context preserves chat history correctly
- **IV5**: Verify context manager works with all knowledge source types (MITRE ATT&CK, man pages, markdown)

---

## Tasks / Subtasks

### Phase 1: Core Context Manager Implementation (AC: 1, 2)

- [ ] **Task 1.1: Create Context Manager Class Structure**
  - [ ] Create cag/context_manager.rb
  - [ ] Define ContextManager class with initialization
  - [ ] Review existing RAG context formatting patterns in rag/rag_manager.rb
  - [ ] Define context configuration parameters (max_tokens, compression_threshold, etc.)
  - [ ] Set up error handling and logging with Print utility

- [ ] **Task 1.2: Implement Document Assembly Interface**
  - [ ] Implement assemble_context(documents, query, options) method
  - [ ] Define Document data structure (content, metadata, relevance_score)
  - [ ] Implement context builder that combines multiple documents
  - [ ] Add document separator formatting for LLM clarity
  - [ ] Implement context metadata tracking (sources, scores)

- [ ] **Task 1.3: Implement Token Counting and Estimation**
  - [ ] Implement token_count(text) method using character-based estimation
  - [ ] Research LLM tokenization patterns for accurate estimation
  - [ ] Add configurable token-to-character ratios for different models
  - [ ] Implement context size validation
  - [ ] Add warnings when approaching context window limits

### Phase 2: Relevance-Based Document Selection (AC: 3)

- [ ] **Task 2.1: Implement Relevance Scoring Integration**
  - [ ] Define relevance score interface for documents
  - [ ] Integrate with knowledge loader's document metadata
  - [ ] Implement sort_by_relevance(documents) method
  - [ ] Add configurable relevance threshold filtering
  - [ ] Implement tie-breaking for equal relevance scores (e.g., recency, source type)

- [ ] **Task 2.2: Implement Intelligent Document Prioritization**
  - [ ] Implement select_top_documents(documents, max_tokens) method
  - [ ] Greedy selection algorithm: add documents until token limit reached
  - [ ] Prioritize high-relevance documents first
  - [ ] Handle partial document inclusion (truncate if needed)
  - [ ] Track selection statistics (total documents, selected count, dropped count)

- [ ] **Task 2.3: Implement Domain-Specific Weighting**
  - [ ] Add cybersecurity domain knowledge weighting
  - [ ] Prioritize MITRE ATT&CK techniques over general documentation
  - [ ] Add source type weights (attack techniques > man pages > general docs)
  - [ ] Implement configurable weighting strategies
  - [ ] Test weighting with sample cybersecurity queries

### Phase 3: Context Window Optimization (AC: 4)

- [ ] **Task 3.1: Implement Context Window Size Management**
  - [ ] Add support for multiple context window sizes (32k, 64k, 128k tokens)
  - [ ] Implement get_context_window_limit(model_name) method
  - [ ] Configure model-specific context window sizes
  - [ ] Add dynamic context allocation (reserve space for query, response, etc.)
  - [ ] Implement context budget management (e.g., 70% knowledge, 20% history, 10% query)

- [ ] **Task 3.2: Implement Context Truncation Strategies**
  - [ ] Implement truncate_context(context, max_tokens) method
  - [ ] Truncation strategy 1: Remove lowest-relevance documents first
  - [ ] Truncation strategy 2: Truncate individual documents proportionally
  - [ ] Preserve critical context sections (e.g., technique names, key commands)
  - [ ] Add truncation warnings and logging

- [ ] **Task 3.3: Implement Context Chunking for Large Knowledge Bases**
  - [ ] Implement semantic chunking for oversized documents
  - [ ] Split documents at natural boundaries (sections, paragraphs)
  - [ ] Preserve context across chunks (overlap strategy)
  - [ ] Track chunk relationships and metadata
  - [ ] Test chunking with large MITRE ATT&CK entries

### Phase 4: Context Compression Techniques (AC: 5)

- [ ] **Task 4.1: Implement Lossless Compression**
  - [ ] Remove redundant whitespace (excess newlines, spaces)
  - [ ] Normalize formatting (consistent spacing, line breaks)
  - [ ] Remove empty sections and duplicate content
  - [ ] Preserve semantic structure and readability
  - [ ] Measure compression ratio achieved

- [ ] **Task 4.2: Implement Lossy Compression for Large Knowledge Bases**
  - [ ] Extract key sentences from paragraphs (summarization)
  - [ ] Remove less critical content (examples, verbose descriptions)
  - [ ] Preserve essential information (technique names, commands, procedures)
  - [ ] Implement compression_level configuration (none, low, medium, high)
  - [ ] Add quality validation for compressed content

- [ ] **Task 4.3: Implement Adaptive Compression**
  - [ ] Implement compress_context(context, target_size) method
  - [ ] Apply lossless compression first
  - [ ] Apply increasing lossy compression if still over target
  - [ ] Track compression statistics (original size, compressed size, ratio)
  - [ ] Log compression warnings when significant content loss occurs

### Phase 5: Multi-Turn Conversation Context Management (AC: 6)

- [ ] **Task 5.1: Implement Conversation History Integration**
  - [ ] Define conversation history data structure (turns, timestamps)
  - [ ] Implement add_conversation_turn(user_msg, bot_response) method
  - [ ] Store recent conversation turns in context
  - [ ] Implement conversation history size limits
  - [ ] Format conversation history for LLM consumption

- [ ] **Task 5.2: Implement Conversation Context Prioritization**
  - [ ] Allocate context budget for conversation history
  - [ ] Implement sliding window for recent N turns
  - [ ] Prioritize recent turns over older turns
  - [ ] Implement conversation compression for long histories
  - [ ] Balance knowledge context vs conversation context

- [ ] **Task 5.3: Implement Context State Management**
  - [ ] Track conversation state across multiple queries
  - [ ] Implement get_conversation_context(conversation_id) method
  - [ ] Persist conversation context in memory
  - [ ] Implement context reset for new conversations
  - [ ] Test multi-turn conversation scenarios

### Phase 6: Context Metadata and Tracking (AC: 7)

- [ ] **Task 6.1: Implement Context Metadata Structure**
  - [ ] Define ContextMetadata class (sources, scores, compression stats)
  - [ ] Track document sources included in context
  - [ ] Track relevance scores for selected documents
  - [ ] Track compression ratio and techniques applied
  - [ ] Track token usage statistics

- [ ] **Task 6.2: Implement Context Quality Metrics**
  - [ ] Calculate context_quality_score based on relevance distribution
  - [ ] Track context_utilization_ratio (used tokens / available tokens)
  - [ ] Measure context_diversity (number of unique sources)
  - [ ] Log context quality metrics for monitoring
  - [ ] Expose metrics via get_context_metadata() method

- [ ] **Task 6.3: Implement Context Debugging and Inspection**
  - [ ] Implement inspect_context() method for debugging
  - [ ] Log context assembly decisions (selected, filtered, compressed)
  - [ ] Add verbose mode for detailed context building logs
  - [ ] Implement context validation checks
  - [ ] Create context summary for troubleshooting

### Phase 7: Integration with Knowledge Loader (AC: 8)

- [ ] **Task 7.1: Integrate with Knowledge Loader Interface**
  - [ ] Review knowledge loader interface from Story 2.2
  - [ ] Consume documents from knowledge loader
  - [ ] Validate document format and metadata
  - [ ] Handle knowledge loader errors gracefully
  - [ ] Test integration with all knowledge source types

- [ ] **Task 7.2: Implement Query-Aware Document Loading**
  - [ ] Pass query to knowledge loader for relevance scoring
  - [ ] Request pre-sorted documents by relevance
  - [ ] Implement lazy loading if knowledge base is very large
  - [ ] Cache frequently used documents
  - [ ] Optimize document loading performance

- [ ] **Task 7.3: Test End-to-End Context Assembly**
  - [ ] Test complete flow: query → knowledge loader → context manager → LLM
  - [ ] Verify context quality for cybersecurity queries
  - [ ] Test with various knowledge source combinations
  - [ ] Validate context formatting for different LLM providers
  - [ ] Measure end-to-end performance

### Phase 8: Testing and Validation (AC: 9)

- [ ] **Task 8.1: Create Unit Tests for Context Manager**
  - [ ] Create test/test_context_manager.rb (or inline in test_cag_comprehensive.rb)
  - [ ] Test document assembly with various input sizes
  - [ ] Test relevance-based selection with known document sets
  - [ ] Test context window optimization with different limits
  - [ ] Test compression techniques with sample documents

- [ ] **Task 8.2: Test Edge Cases and Error Handling**
  - [ ] Test with empty document list
  - [ ] Test with single very large document (exceeds context window)
  - [ ] Test with all low-relevance documents
  - [ ] Test with invalid token limits (0, negative, very large)
  - [ ] Test context manager with missing/corrupted documents

- [ ] **Task 8.3: Test Multi-Turn Conversation Scenarios**
  - [ ] Test conversation history tracking across multiple turns
  - [ ] Test context budget allocation between knowledge and history
  - [ ] Test conversation state persistence
  - [ ] Test conversation reset functionality
  - [ ] Verify no conversation leakage between different users

- [ ] **Task 8.4: Integration Verification** (IV1-IV5)
  - [ ] **IV1**: Test context sizes stay within model limits (32k, 64k, 128k)
  - [ ] **IV2**: Verify high-relevance docs appear first in context
  - [ ] **IV3**: Validate compressed context maintains accuracy (manual review)
  - [ ] **IV4**: Test multi-turn conversation context preservation
  - [ ] **IV5**: Test with MITRE ATT&CK, man pages, markdown sources

---

## Dev Notes

### Context Manager Architecture

**Context Manager** (`cag/context_manager.rb`):
- Main component for assembling and optimizing context for CAG inference
- Responsibilities: document selection, context assembly, compression, window management
- Integration points: knowledge_loader (Story 2.2), cache_manager (Story 2.4)
- [Source: docs/stories/epic-2-cag-system-implementation.md#126-134]

**Key Design Principles**:
- **Relevance-first**: Prioritize most relevant documents for query
- **Token efficiency**: Maximize information density within context window
- **Semantic preservation**: Compression must maintain meaning
- **Adaptability**: Support different model context window sizes
- [Source: docs/prd.md#383-407]

### Context Window Management Strategy

**Target Context Sizes**:
- Small models: 32k tokens (e.g., Llama 3.1 32k variant)
- Medium models: 64k tokens
- Large models: 128k tokens (e.g., GPT-4 Turbo, Claude 2+)
- [Source: docs/stories/epic-2-cag-system-implementation.md#383-389]

**Context Budget Allocation**:
- Knowledge base content: ~70% of context window
- Conversation history: ~20% of context window
- Query and system prompt: ~10% of context window

**Token Estimation**:
- Average English: ~4 characters per token
- Technical content: ~3.5 characters per token (more specialized vocabulary)
- Code/commands: ~3 characters per token (shorter tokens)
- Use configurable ratios for accuracy

### Document Prioritization Strategy

**Relevance Scoring**:
- Cosine similarity to query (if using embeddings)
- Keyword match scores
- Source type weights (MITRE > man pages > general docs)
- Recency (if applicable)
- [Source: docs/stories/epic-2-cag-system-implementation.md#383-407]

**Cybersecurity Domain Weighting**:
```ruby
# Example weighting configuration
SOURCE_WEIGHTS = {
  'mitre_attack' => 1.5,      # Highest priority for attack techniques
  'man_pages' => 1.2,          # Command documentation
  'lab_sheets' => 1.3,         # Lab-specific content
  'markdown_docs' => 1.0       # General documentation
}
```

**Selection Algorithm**:
1. Sort documents by weighted relevance score (descending)
2. Greedily add documents to context until token budget reached
3. If last document doesn't fit, optionally truncate or skip
4. Track selection statistics for logging

### Context Compression Techniques

**Lossless Compression**:
- Remove excess whitespace (multiple newlines → single newline)
- Normalize spacing (multiple spaces → single space)
- Remove empty sections and duplicate content
- Expected compression ratio: ~10-20%

**Lossy Compression** (for large knowledge bases):
- Extract key sentences using heuristics:
  - First sentence of each paragraph (usually topic sentence)
  - Sentences with keywords matching query
  - Sentences with cybersecurity terminology
- Remove verbose explanations and examples
- Keep essential information (technique names, commands, procedures)
- Expected compression ratio: ~30-50% (more aggressive)

**Adaptive Compression Example**:
```ruby
def compress_context(context, target_tokens)
  current_tokens = token_count(context)

  # Try lossless first
  compressed = lossless_compress(context)
  return compressed if token_count(compressed) <= target_tokens

  # Apply increasing lossy compression
  compression_levels = [:low, :medium, :high]
  compression_levels.each do |level|
    compressed = lossy_compress(compressed, level)
    return compressed if token_count(compressed) <= target_tokens
  end

  # Last resort: hard truncate
  hard_truncate(compressed, target_tokens)
end
```

### Multi-Turn Conversation Context

**Conversation History Format**:
```ruby
# Example conversation turn structure
{
  turns: [
    {
      timestamp: Time.now,
      user: 'attacker1',
      user_message: 'How do I dump credentials?',
      bot_response: 'You can use mimikatz...',
      knowledge_sources: ['T1003']  # Track which knowledge was used
    },
    # ... more turns
  ]
}
```

**Conversation Context Management**:
- Store last N turns (configurable, default: 5-10 turns)
- Format for LLM consumption with clear user/assistant labels
- Allocate fixed token budget for conversation history
- Compress or truncate older turns if necessary
- Reset conversation context when topic changes significantly

### Integration with Knowledge Loader

**Knowledge Loader Interface** (from Story 2.2):
```ruby
# Expected interface from knowledge_loader.rb
loader = KnowledgeLoader.new(config)
documents = loader.load_documents(query: 'credential dumping', max_docs: 100)

# Document structure expected
document = {
  content: 'Credential Dumping (T1003)...',
  metadata: {
    source_type: 'mitre_attack',
    id: 'T1003',
    title: 'Credential Dumping',
    relevance_score: 0.95
  }
}
```

**Context Manager Usage**:
```ruby
# Initialize context manager
context_manager = ContextManager.new(
  max_context_tokens: 64_000,
  compression_level: :medium,
  model_name: 'llama-3.1-32k'
)

# Assemble context for query
context_result = context_manager.assemble_context(
  documents: loaded_documents,
  query: 'How do I dump credentials?',
  conversation_history: previous_turns
)

# Result structure
{
  context: "...",  # Formatted context string ready for LLM
  metadata: {
    total_documents: 100,
    selected_documents: 15,
    total_tokens: 48_500,
    compression_ratio: 0.75,
    sources: ['T1003', 'T1078', ...],
    quality_score: 0.88
  }
}
```

### Testing Strategy

**Unit Test Coverage**:
- Document assembly with various document counts (0, 1, 10, 100+)
- Relevance-based selection with known relevance scores
- Token counting accuracy (test with sample texts)
- Context window limits (test at boundary, over limit, under limit)
- Compression techniques (lossless, lossy, adaptive)
- Conversation history management (add turns, truncate, reset)

**Edge Cases**:
- Empty document list → should return minimal context with query only
- Single oversized document → should truncate or compress to fit
- All documents exceed context window → should select most relevant subset
- Invalid token limits (0, negative) → should raise error or use default
- Conversation history exceeds budget → should truncate oldest turns

**Integration Tests**:
- Full flow: query → knowledge_loader → context_manager → formatted context
- Test with real knowledge sources (MITRE ATT&CK, man pages)
- Validate context format for different LLM providers
- Performance testing (context assembly should complete in <1 second)

### Performance Considerations

**Context Assembly Performance**:
- Target: <1 second for typical context assembly (100 documents)
- Optimize sorting algorithms for large document sets
- Cache token counts for documents when possible
- Lazy evaluation for compression (only compress if needed)

**Memory Usage**:
- Keep only selected documents in memory
- Release filtered documents early
- Stream compression for very large documents
- Monitor memory usage during testing

### Error Handling

**Error Scenarios**:
- Knowledge loader returns no documents → use fallback context
- Token counting fails → use character-based estimation
- Compression fails → skip compression, use original content
- Context exceeds window after assembly → hard truncate with warning
- Invalid conversation history → log error, proceed without history

**Error Handling Pattern**:
```ruby
def assemble_context(documents, query, options = {})
  begin
    # Context assembly logic
  rescue => e
    Print.err("Context assembly failed: #{e.message}")
    # Return minimal fallback context
    return {
      context: "Query: #{query}\n\nNo knowledge base context available.",
      metadata: { error: e.message }
    }
  end
end
```

### Configuration Options

**Context Manager Configuration**:
```ruby
config = {
  max_context_tokens: 64_000,          # Model context window size
  compression_level: :medium,          # :none, :low, :medium, :high
  compression_threshold: 0.9,          # Compress if utilization > 90%
  knowledge_budget_ratio: 0.7,         # 70% for knowledge
  conversation_budget_ratio: 0.2,      # 20% for history
  query_budget_ratio: 0.1,             # 10% for query/system
  min_relevance_score: 0.3,            # Filter docs below this score
  max_conversation_turns: 10,          # Keep last 10 turns
  source_weights: {                    # Domain-specific weights
    'mitre_attack' => 1.5,
    'man_pages' => 1.2,
    'markdown_docs' => 1.0
  },
  model_name: 'llama-3.1-32k'          # For model-specific optimization
}
```

### Implementation Notes

**Code Organization**:
```ruby
# cag/context_manager.rb structure
class ContextManager
  def initialize(config)
    # Setup configuration, token estimator, etc.
  end

  # Main interface
  def assemble_context(documents, query, options = {})
    # Core context assembly logic
  end

  # Document selection
  def select_documents(documents, max_tokens)
    # Relevance-based selection
  end

  # Context optimization
  def optimize_context(context, target_tokens)
    # Compression and truncation
  end

  # Conversation management
  def add_conversation_turn(user_msg, bot_response)
    # Track conversation history
  end

  # Utilities
  def token_count(text)
    # Token estimation
  end

  def compress_context(context, target_tokens)
    # Adaptive compression
  end

  # Metadata
  def get_context_metadata
    # Return context statistics
  end
end
```

**Dependencies**:
- KnowledgeLoader (from Story 2.2) - for document loading
- No external gems required (use Ruby standard library)
- Print utility for logging

---

## Testing

### Testing Strategy for This Story

**Unit Testing Approach**:
1. Test each method independently with known inputs
2. Verify token counting accuracy with sample texts
3. Test document selection with controlled relevance scores
4. Validate compression maintains semantic meaning
5. Test conversation history management across multiple turns

### Test Execution Commands

```bash
# Run context manager tests (if separate file)
ruby test/test_context_manager.rb

# Run as part of CAG comprehensive tests
ruby test/test_cag_comprehensive.rb

# Run with verbose output
ruby test/test_context_manager.rb --verbose

# Run in Nix environment
nix develop
ruby test/test_context_manager.rb
```

### Success Criteria

✅ Context manager assembles documents into optimized context
✅ Relevance-based selection prioritizes high-scoring documents
✅ Context window optimization respects token limits
✅ Compression techniques reduce size while preserving meaning
✅ Multi-turn conversation context managed correctly
✅ All unit tests pass
✅ Integration with knowledge loader validated
✅ Context metadata tracking functional

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-23 | v1.0 | Initial story creation | SM Agent |

---

## Dev Agent Record

_This section will be populated by the development agent during implementation._

### Agent Model Used

_To be filled by dev agent_

### Debug Log References

_To be filled by dev agent_

### Completion Notes

_To be filled by dev agent_

### File List

_To be filled by dev agent_

---

## QA Results

_This section will be populated by QA Agent after story completion._

---

**Story prepared by**: Scrum Master Agent
**Ready for**: Developer Agent implementation (after Story 2.2 completion)
**Next Story**: 2.4 - Implement Cache Manager (depends on this story completion)
